# Predicting Medical Insurance Costs  

## Описание  
Проект посвящён прогнозированию индивидуальных медицинских расходов на основе демографических и медицинских факторов.  
Используется датасет **insurance**, содержащий данные о возрасте, поле, индексе массы тела, курении, регионе проживания и итоговой стоимости медицинской страховки.  

Задача: построить модель линейной регрессии, которая предсказывает медицинские расходы клиента.  

---

## Цели проекта
- Провести предобработку данных (работа с категориальными признаками, преобразование признаков).  
- Исследовать зависимости между признаками и целевой переменной.  
- Обучить модель линейной регрессии и оценить её качество.  
- Сделать предсказание стоимости страховки для конкретного человека.  

---

## Технологии
- Python 3  
- Pandas, NumPy  
- Scikit-learn  
- Jupyter Notebook / Google colab

---

## Этапы работы
1. Загрузка и изучение данных.  
2. Очистка данных и кодирование категориальных признаков (sex, smoker, region).  
3. Формирование обучающей и тестовой выборки.  
4. Обучение модели линейной регрессии.  
5. Оценка качества модели с помощью **Mean Squared Error (MSE)**.  
6. Предсказание стоимости страховки для конкретного клиента.  

---

## Результаты
- Модель обучена на 1338 записях.  
- Ошибка на тестовой выборке (**MSE**) = 33 721 836 ($5 9807, 05).
- На тренировочной выборке (**MSE**) = 37 335 183 ($6 110, 25).  
- Пример предсказания: для клиента 22 лет, некурящего, с BMI=31.35, модель предсказала стоимость страховки ≈ **$4060**.  

Ошибки примерно одинаковые (разница небольшая).
Модель не переобучилась и не недообучилась - она ведёт себя стабильно на обеих выборках.

Значения MSE большие по числу. То есть средняя ошибка предсказания около 6 тыс $ - это довольно много, если учесть, что средние расходы в датасете примерно 13 тыс $.

Вывод по модели линейной регрессии:
- Она улавливает общие зависимости, но предсказания не очень точные.
- Линейная модель плохо справляется с нелинейными зависимостями (например, эффект курения, возраста и BMI вместе).

Поэтому проведены допол-но предсказания с помощью других моделей:
1. Random Forest:
Значительно меньше MSE и RMSE, чем у Linear Regression.
Модель умеет работать с нелинейными зависимостями и взаимодействиями признаков.
2. Gradient Boosting
Лучший результат по RMSE ($4565.87).
Подтверждает, что ансамблевые методы бустинга хорошо подходят для этой задачи.
3. Настроенный XGBoost - лучший выбор для нашего датасета. Модель учитывает нелинейные зависимости и не переобучается (благодаря маленькому learning_rate и небольшой глубине дерева).

---

## Пример использования
```python
data = [{
    "age": 22,
    "sex": 1,
    "bmi": 31.350,
    "children": 1,
    "smoker": 0,
    "region_northeast": 0,
    "region_northwest": 1,
    "region_southeast": 0,
    "region_southwest": 0
}]

df_person = pd.DataFrame(data)
prediction = lr.predict(df_person)
print(prediction)